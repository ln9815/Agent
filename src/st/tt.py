import streamlit as st
import requests
import json
import time
import queue
import threading
import logging
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime
import os
from thx.thx_tool import ThxApi
from typing import Optional, Dict, List, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
TOKEN = 'app-rCFXuZN6Bwr4P3c5VDsknOt4'
LOG_DIR = 'logs'
DATA_LOG_PREFIX = 'data_'
LOG_FORMAT = '%(asctime)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
DATE_FORMAT = '%Y-%m-%d %H:%M:%S'
DEFAULT_STOCK_CODE = 'HK2018'

# åˆ›å»ºå¿…è¦çš„ç›®å½•
os.makedirs(LOG_DIR, exist_ok=True)

# è®¾ç½®æ•°æ®è®°å½•å™¨
data_logger = logging.getLogger('StockData')
data_logger.setLevel(logging.INFO)
file_handler = logging.handlers.TimedRotatingFileHandler(
    filename=f'{LOG_DIR}/stock_app.log',
    when='midnight',
    interval=1,
    backupCount=30,
    encoding='utf-8'
)
file_handler.setFormatter(logging.Formatter(LOG_FORMAT, datefmt=DATE_FORMAT))
data_logger.addHandler(file_handler)

# é…ç½®Streamlité¡µé¢
st.set_page_config(page_title="æŠ•èµ„å°ç§˜", layout="wide")

def log_stock_data(stock_code: str, data_type: str, data: dict):
    """è®°å½•è‚¡ç¥¨æ•°æ®"""
    try:
        def convert_timestamps(obj):
            if isinstance(obj, pd.Timestamp):
                return obj.strftime(DATE_FORMAT)
            elif isinstance(obj, dict):
                return {k: convert_timestamps(v) for k, v in obj.items()}
            elif isinstance(obj, (list, tuple)):
                return [convert_timestamps(item) for item in obj]
            return obj

        serializable_data = convert_timestamps(data)
        
        log_entry = {
            'timestamp': datetime.now().strftime(DATE_FORMAT),
            'stock_code': stock_code,
            'data_type': data_type,
            'data': serializable_data
        }
        
        data_log_path = f'{LOG_DIR}/{DATA_LOG_PREFIX}{datetime.now().strftime("%Y%m%d")}.json'
        with open(data_log_path, 'a', encoding='utf-8') as f:
            json.dump(log_entry, f, ensure_ascii=False)
            f.write('\n')
        
        data_logger.info(f"æ•°æ®è®°å½• - è‚¡ç¥¨ä»£ç : {stock_code}, ç±»å‹: {data_type}")
    except Exception as e:
        data_logger.error(f"æ•°æ®è®°å½•å¤±è´¥: {str(e)}")

def filter_trading_hours(df, is_intraday=False, is_hk=False):
    """è¿‡æ»¤éäº¤æ˜“æ—¶é—´çš„æ•°æ®ç‚¹"""
    if is_intraday:
        df = df.copy()
        df['time_only'] = df['t'].dt.time
        
        if is_hk:
            trade_time = [('09:30:00', '12:00:00'), ('13:00:00', '16:10:00')]
        else:
            trade_time = [('09:30:00', '11:30:00'), ('13:00:00', '15:00:00')]
        
        conditions = []
        for start, end in trade_time:
            start_time = pd.to_datetime(start).time()
            end_time = pd.to_datetime(end).time()
            conditions.append((df['time_only'] >= start_time) & (df['time_only'] <= end_time))
        
        combined_condition = conditions[0]
        for cond in conditions[1:]:
            combined_condition |= cond
        
        df = df[combined_condition]
        df = df.drop(columns=['time_only'])
    else:
        df = df.dropna(subset=['o', 'h', 'l', 'c'])
    
    return df

def convert_datetime_column(df, column_name):
    """å¤„ç†æ—¥æœŸæ—¶é—´åˆ—çš„è½¬æ¢"""
    if column_name not in df.columns:
        return df, "ç¼ºå°‘æ—¶é—´åˆ—"
    
    formats = [
        '%Y%m%d', '%Y-%m-%d', '%Y/%m/%d', 
        '%m/%d/%Y', '%d/%m/%Y'
    ]
    
    for fmt in formats:
        try:
            df[column_name] = pd.to_datetime(df[column_name], format=fmt, errors='coerce')
            if not df[column_name].isnull().any():
                return df, None
        except:
            continue
    
    try:
        df[column_name] = pd.to_datetime(df[column_name], errors='coerce')
    except Exception as e:
        return df, f"æ—¶é—´è½¬æ¢å¤±è´¥: {str(e)}"
    
    if df[column_name].isnull().any():
        failed_values = df.loc[df[column_name].isnull(), column_name].unique()
        failed_sample = failed_values[0] if len(failed_values) > 0 else "N/A"
        return df, f"æ— æ³•è½¬æ¢çš„æ—¶é—´å€¼: {failed_sample} (æ ·æœ¬)"
    
    return df, None

def create_candlestick_chart(df: pd.DataFrame, title: str, stock_code: str, is_intraday=False):
    """åˆ›å»ºè‚¡ç¥¨å›¾è¡¨"""
    is_hk = stock_code.startswith('HK') or stock_code.startswith('hk')
    currency_unit = 'HKD' if is_hk else 'CNY'
    df = filter_trading_hours(df, is_intraday=is_intraday, is_hk=is_hk)
    
    if df.empty:
        fig = go.Figure()
        fig.update_layout(
            title=title,
            xaxis_title='æ—¶é—´' if is_intraday else 'æ—¥æœŸ',
            yaxis_title=f'ä»·æ ¼ ({currency_unit})',
            annotations=[dict(
                text="æ— å¯ç”¨æ•°æ®",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False,
                font=dict(size=20)
            )]
        )
        return fig
    
    try:
        fig = make_subplots(
            rows=2, cols=1, 
            shared_xaxes=True, 
            vertical_spacing=0.05,
            row_heights=[0.7, 0.3]
        )
        
        if is_intraday:
            if 'v' in df.columns and 'c' in df.columns:
                df['cum_amount'] = (df['c'] * df['v']).cumsum()
                df['cum_volume'] = df['v'].cumsum()
                df['avg_price'] = df['cum_amount'] / df['cum_volume']
            else:
                df['avg_price'] = df['c'].rolling(window=5, min_periods=1).mean()
            
            price_trace = go.Scatter(
                x=df['t'],
                y=df['c'],
                mode='lines',
                name='ä»·æ ¼',
                line=dict(color='blue', width=2)
            )
            fig.add_trace(price_trace, row=1, col=1)
            
            avg_trace = go.Scatter(
                x=df['t'],
                y=df['avg_price'],
                mode='lines',
                name='å‡ä»·',
                line=dict(color='orange', width=2, dash='dash')
            )
            fig.add_trace(avg_trace, row=1, col=1)
            
            if 'prev_close' in df.columns and not df['prev_close'].isnull().all():
                prev_close = df['prev_close'].iloc[0]
                fig.add_hline(
                    y=prev_close, 
                    line=dict(color='gray', width=1, dash='dash'),
                    annotation_text=f"æ˜¨æ”¶: {prev_close:.2f}",
                    row=1, col=1
                )
        else:
            candle_trace = go.Candlestick(
                x=df['t'],
                open=df['o'],
                high=df['h'],
                low=df['l'],
                close=df['c'],
                increasing_line_color='red',
                decreasing_line_color='green',
                name='Kçº¿'
            )
            fig.add_trace(candle_trace, row=1, col=1)
        
        if 'v' in df.columns:
            colors = ['red'] * len(df)
            for i in range(len(df)):
                if i == 0:
                    if 'prev_close' in df.columns and not pd.isnull(df['prev_close'].iloc[0]):
                        if df['c'].iloc[i] < df['prev_close'].iloc[0]:
                            colors[i] = 'green'
                else:
                    if df['c'].iloc[i] < df['c'].iloc[i-1]:
                        colors[i] = 'green'
            
            volume_bars = go.Bar(
                x=df['t'],
                y=df['v'],
                name='æˆäº¤é‡',
                marker_color=colors,
                showlegend=False
            )
            fig.add_trace(volume_bars, row=2, col=1)
            has_volume = True
        else:
            has_volume = False
        
        if not is_intraday and len(df) > 5 and 'c' in df.columns:
            try:
                df['MA5'] = df['c'].rolling(window=5, min_periods=1).mean()
                fig.add_trace(go.Scatter(
                    x=df['t'],
                    y=df['MA5'],
                    mode='lines',
                    name='MA5',
                    line=dict(color='orange', width=2)
                ), row=1, col=1)
                
                if len(df) > 20:
                    df['MA20'] = df['c'].rolling(window=20, min_periods=1).mean()
                    fig.add_trace(go.Scatter(
                        x=df['t'],
                        y=df['MA20'],
                        mode='lines',
                        name='MA20',
                        line=dict(color='purple', width=2)
                    ), row=1, col=1)
            except Exception as e:
                data_logger.warning(f"æ·»åŠ ç§»åŠ¨å¹³å‡çº¿å¤±è´¥: {str(e)}")
        
        layout_params = {
            'title': title,
            'height': 700,
            'legend': dict(
                orientation='h',
                yanchor='bottom',
                y=1.02,
                xanchor='right',
                x=1
            )
        }
        
        if is_intraday:
            if is_hk:
                rangebreaks = [
                    dict(bounds=[12, 13], pattern="hour"),
                    dict(bounds=[16, 9.5], pattern="hour"),
                    dict(bounds=["sat", "mon"])
                ]
            else:
                rangebreaks = [
                    dict(bounds=[11.5, 13], pattern="hour"),
                    dict(bounds=[15, 9.5], pattern="hour"),
                    dict(bounds=["sat", "mon"])
                ]
            
            layout_params.update({
                'xaxis': {
                    'type': 'date',
                    'tickformat': '%H:%M',
                    'rangebreaks': rangebreaks,
                    'rangeslider': dict(visible=False)
                },
                'xaxis2': {
                    'type': 'date',
                    'tickformat': '%H:%M',
                    'rangebreaks': rangebreaks
                }
            })
        else:
            layout_params.update({
                'xaxis': {
                    'type': 'date',
                    'tickformat': '%Y-%m-%d',
                    'rangeslider': dict(visible=False)
                },
                'xaxis2': {
                    'type': 'date',
                    'tickformat': '%Y-%m-%d'
                }
            })
        
        fig.update_layout(**layout_params)
        fig.update_yaxes(title_text=f"ä»·æ ¼ ({currency_unit})", row=1, col=1)
        
        if has_volume:
            fig.update_yaxes(title_text="æˆäº¤é‡", row=2, col=1)
        else:
            fig.update_layout(row_heights=[1.0, 0])
        
        return fig
            
    except Exception as e:
        data_logger.error(f"åˆ›å»ºå›¾è¡¨å¤±è´¥: {str(e)}", exc_info=True)
        fig = go.Figure(data=[go.Scatter(
            x=df['t'],
            y=df['c'],
            mode='lines+markers',
            name='æ”¶ç›˜ä»·',
            line=dict(color='blue', width=2))
        ])
        fig.update_layout(title=title)
        return fig

def display_stock_info(stock_code: str) -> Optional[Dict[str, Any]]:
    """æ˜¾ç¤ºè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    is_hk = stock_code.startswith('HK') or stock_code.startswith('hk')
    currency_unit = 'HKD' if is_hk else 'CNY'
    try:
        api = ThxApi(stock_code)
        info = api.basic_info()
        
        log_stock_data(stock_code, "basic_info", info)
        
        if not info:
            data_logger.warning(f"è·å–åˆ°ç©ºçš„åŸºæœ¬ä¿¡æ¯ - è‚¡ç¥¨ä»£ç : {stock_code}")
            st.warning("æœªè·å–åˆ°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
            return None
        
        st.subheader(f"{info.get('è‚¡ç¥¨åç§°', 'N/A')} ({info.get('è‚¡ç¥¨ç¼–ç ', 'N/A')})")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å½“å‰ä»·æ ¼", f"{info.get('æ”¶ç›˜', 'N/A')} {currency_unit}")
            st.metric("æ¶¨è·Œå¹…", f"{info.get('æ¶¨å¹…(%)', 'N/A')}%", 
                      delta=f"{info.get('æ¶¨å¹…', 'N/A')}", delta_color="inverse")
            st.metric("æˆäº¤é‡", f"{float(info.get('æˆäº¤é‡', 'N/A'))/1000000:.2f}ä¸‡æ‰‹")
        
        with col2:
            st.metric("æ˜¨æ”¶", f"{info.get('æ˜¨æ”¶', 'N/A')} {currency_unit}")
            st.metric("æœ€é«˜ä»·/æœ€ä½ä»·", 
                     f"{info.get('æœ€é«˜', 'N/A')}/{info.get('æœ€ä½', 'N/A')} {currency_unit}")
            st.metric("æˆäº¤é¢", f"{float(info.get('æˆäº¤é¢', 'N/A'))/100000000:.2f}äº¿ {currency_unit}")
        
        with col3:
            st.metric("å¼€ç›˜", f"{info.get('å¼€ç›˜', 'N/A')} {currency_unit}")
            st.metric("å¸‚ç›ˆç‡", f"{info.get('å¸‚ç›ˆç‡', 'N/A')}")
            st.metric("å¸‚ç›ˆç‡(åŠ¨)", f"{info.get('å¸‚ç›ˆç‡(åŠ¨)', 'N/A')}")
        
        with col4:
            st.metric("æŒ¯å¹…", f"{info.get('æŒ¯å¹…', 'N/A')}%")
            st.metric("æ¢æ‰‹ç‡", f"{info.get('æ¢æ‰‹ç‡', 'N/A')}%")
            st.metric("å¸‚å‡€ç‡", f"{info.get('å¸‚å‡€ç‡', 'N/A')}")
        
        return info
    except Exception as e:
        data_logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥ - è‚¡ç¥¨ä»£ç : {stock_code}, é”™è¯¯: {str(e)}")
        st.error(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

def display_chart(stock_code: str, chart_type: str = 'realtime'):
    """æ˜¾ç¤ºKçº¿å›¾ï¼ˆå®æ—¶æˆ–å†å²ï¼‰"""
    try:
        data_logger.info(f"å¼€å§‹è·å–{chart_type}æ•°æ®ï¼Œè‚¡ç¥¨ä»£ç : {stock_code}")
        api = ThxApi(stock_code)
        
        if chart_type == 'realtime':
            data = api.last(period='1m')
            data_type = "realtime_data"
            title = f'{stock_code} å®æ—¶Kçº¿å›¾ (5åˆ†é’Ÿ)'
        else:
            try:
                data = api.history(period='d', count=90)
                data_type = "history_data"
                title = f'{stock_code} å†å²Kçº¿å›¾ (90å¤©)'
            except Exception as api_error:
                data_logger.warning(f"ä½¿ç”¨é»˜è®¤å‚æ•°è·å–å†å²æ•°æ®å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•: {str(api_error)}")
                data = api.history(period='1d', count=90)
                data_type = "history_data"
                title = f'{stock_code} å†å²Kçº¿å›¾ (90å¤©)'
        
        if not data:
            data_logger.error(f"è·å–{chart_type}æ•°æ®ä¸ºç©º - è‚¡ç¥¨ä»£ç : {stock_code}")
            st.error(f"è·å–{chart_type}æ•°æ®å¤±è´¥: è¿”å›æ•°æ®ä¸ºç©º")
            return
            
        def convert_numeric_fields(obj):
            if isinstance(obj, dict):
                return {k: convert_numeric_fields(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numeric_fields(item) for item in obj]
            elif isinstance(obj, str):
                clean_str = obj.replace(',', '').replace(' ', '')
                if clean_str.replace('.', '', 1).replace('-', '', 1).isdigit():
                    return float(clean_str)
            return obj

        processed_data = convert_numeric_fields(data)
        log_stock_data(stock_code, data_type, processed_data)
        
        df = pd.DataFrame(processed_data)
        
        required_columns = ['t', 'o', 'h', 'l', 'c']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            data_logger.error(f"æ•°æ®ç¼ºå¤±å¿…è¦åˆ—: {missing_columns}")
            st.error(f"æ•°æ®æ ¼å¼é”™è¯¯: ç¼ºå°‘å¿…è¦çš„åˆ— {', '.join(missing_columns)}")
            return
            
        try:
            df['t'] = pd.to_datetime(df['t'])
        except Exception as e:
            data_logger.error(f"æ—¶é—´è½¬æ¢å¤±è´¥: {str(e)}")
            st.error("æ—¶é—´æ•°æ®å¤„ç†å¤±è´¥")
            return
            
        numeric_cols = ['o', 'h', 'l', 'c']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        if df[numeric_cols].isnull().values.any():
            data_logger.warning(f"æ•°æ®åŒ…å«NaNå€¼ï¼Œå°†å°è¯•å¡«å……")
            df[numeric_cols] = df[numeric_cols].fillna(method='ffill')
        
        df, error = convert_datetime_column(df, 't')
        if error:
            data_logger.error(error)
            st.error("æ—¶é—´æ•°æ®å¤„ç†å¤±è´¥")
            return
            
        if not pd.api.types.is_datetime64_any_dtype(df['t']):
            data_logger.error("æ—¶é—´åˆ—è½¬æ¢åä»ä¸æ˜¯datetimeç±»å‹")
            st.error("æ—¶é—´æ•°æ®å¤„ç†å¤±è´¥")
            return
        
        try:
            fig = create_candlestick_chart(
                df, 
                title,
                stock_code,
                is_intraday=(chart_type == 'realtime')
            )
            st.plotly_chart(fig, use_container_width=True)
            data_logger.info(f"æˆåŠŸæ˜¾ç¤º{chart_type}å›¾è¡¨")
        except Exception as e:
            data_logger.error(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {str(e)}")
            st.error(f"ç»˜åˆ¶{chart_type}å›¾è¡¨å¤±è´¥")
            
    except Exception as e:
        data_logger.error(f"è·å–{chart_type}æ•°æ®å¤±è´¥ - è‚¡ç¥¨ä»£ç : {stock_code}", exc_info=True)
        st.error(f"è·å–{chart_type}æ•°æ®å¤±è´¥: {str(e)}")

def display_news(stock_code: str):
    """æ˜¾ç¤ºè‚¡ç¥¨æ–°é—»"""
    try:
        if not stock_code or not isinstance(stock_code, str):
            data_logger.warning(f"æ— æ•ˆçš„è‚¡ç¥¨ä»£ç : {stock_code}")
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
            return

        data_logger.info(f"å¼€å§‹è·å–æ–°é—»æ•°æ®ï¼Œè‚¡ç¥¨ä»£ç : {stock_code}")
        
        api = ThxApi(stock_code)
        news_data = api.news(count=10)
        
        if not news_data:
            data_logger.warning(f"è·å–åˆ°ç©ºçš„æ–°é—»æ•°æ® - è‚¡ç¥¨ä»£ç : {stock_code}")
            st.warning("æš‚æ— ç›¸å…³æ–°é—»")
            return
            
        if not isinstance(news_data, list):
            data_logger.error(f"æ–°é—»æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼ŒæœŸæœ›åˆ—è¡¨ï¼Œå¾—åˆ°: {type(news_data)}")
            st.error("æ–°é—»æ•°æ®æ ¼å¼é”™è¯¯")
            return

        processed_news = []
        for news_item in news_data:
            try:
                if not isinstance(news_item, dict):
                    continue
                processed_item = {
                    'date': str(news_item.get('date', 'æ— æ—¥æœŸ')),
                    'title': str(news_item.get('title', 'æ— æ ‡é¢˜')),
                    'summary': str(news_item.get('summary', 'æ— å†…å®¹æ‘˜è¦')),
                    'href': str(news_item.get('href', '#')),
                }
                processed_news.append(processed_item)
            except Exception as e:
                data_logger.error(f"å¤„ç†å•æ¡æ–°é—»å¤±è´¥: {str(e)}", exc_info=True)
        
        log_stock_data(stock_code, "news_data", processed_news)
        
        st.subheader("æœ€æ–°æ–°é—»")
        for news in processed_news:
            try:
                with st.expander(f"{news['date']} - {news['title']}"):
                    st.write(news['summary'])
                    if news['href'] and news['href'] != '#':
                        st.markdown(f"[é˜…è¯»å…¨æ–‡]({news['href']})")
            except Exception as e:
                data_logger.error(f"æ˜¾ç¤ºå•æ¡æ–°é—»å¤±è´¥: {str(e)}", exc_info=True)
                continue
                
        data_logger.info(f"æˆåŠŸæ˜¾ç¤º {len(processed_news)} æ¡æ–°é—»")
        
    except Exception as e:
        data_logger.error(f"è·å–æ–°é—»å¤±è´¥ - è‚¡ç¥¨ä»£ç : {stock_code}", exc_info=True)
        st.error(f"è·å–æ–°é—»å¤±è´¥: {str(e)}")

class WorkflowRunner:
    """æ‰§è¡Œè‚¡ç¥¨åˆ†æå·¥ä½œæµ"""
    def __init__(self, stock_code):
        self.stock_code = stock_code
        self.text_queue = queue.Queue()
        self.log_queue = queue.Queue()
        self.finished = False
        self.error = None

    def run(self):
        """åœ¨å·¥ä½œçº¿ç¨‹ä¸­æ‰§è¡Œå·¥ä½œæµ"""
        try:
            workflow_url = "http://szvkt.top:8880/v1/workflows/run"
            headers = {
                "Authorization": f"Bearer {TOKEN}",
                "Content-Type": "application/json",
                "Accept": "text/event-stream"
            }

            data = {
                "inputs": {
                    "stock_code": self.stock_code
                },
                "response_mode": "streaming",
                "user": "streamlit_user"
            }

            full_text = ""
            with requests.post(
                workflow_url,
                headers=headers,
                json=data,
                stream=True,
                timeout=300
            ) as response:
                
                if response.status_code != 200:
                    self.error = f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}\nå“åº”å†…å®¹: {response.text}"
                    return
                
                buffer = ""
                for byte_chunk in response.iter_content(chunk_size=1024):
                    if byte_chunk:
                        chunk = byte_chunk.decode('utf-8')
                        buffer += chunk
                        
                        while "\n\n" in buffer:
                            event_end = buffer.index("\n\n")
                            event_data = buffer[:event_end]
                            buffer = buffer[event_end + 2:]
                            
                            result = self.process_event_data(event_data)
                            if result:
                                event_type, text, log = result
                                
                                if event_type == "text_chunk":
                                    full_text += text
                                    self.text_queue.put(full_text)
                                
                                if log:
                                    self.log_queue.put(log)
            
            self.text_queue.put(full_text)
            self.log_queue.put("ğŸ å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        
        except requests.exceptions.RequestException as e:
            self.error = f"âŒ è¯·æ±‚å¤±è´¥: {str(e)}"
        except Exception as e:
            self.error = f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}"
        finally:
            self.finished = True

    def process_event_data(self, event_data):
        """å¤„ç†å•ä¸ªSSEäº‹ä»¶æ•°æ®"""
        try:
            event_lines = event_data.split('\n')
            event_dict = {}
            
            for line in event_lines:
                if line.startswith('data:'):
                    json_str = line[5:].strip()
                    if json_str:
                        event_dict = json.loads(json_str)
            
            if not event_dict:
                return None
            
            event_type = event_dict.get('event')
            text_output = ""
            log_output = ""
            
            if event_type == 'workflow_started':
                log_output = f"â±ï¸ [å·¥ä½œæµå¼€å§‹] ID: {event_dict['data']['id']}\nä»»åŠ¡ID: {event_dict['task_id']}"
            
            elif event_type == 'node_started':
                log_output = f"ğŸš€ [èŠ‚ç‚¹å¼€å§‹] {event_dict['data']['title']} (ç±»å‹: {event_dict['data']['node_type']})"
            
            elif event_type == 'text_chunk':
                text_output = event_dict['data']['text']
            
            elif event_type == 'node_finished':
                node_data = event_dict['data']
                status = node_data['status']
                if status == 'failed':
                    log_output = f"âŒ [èŠ‚ç‚¹å¤±è´¥] {node_data['node_id']} - é”™è¯¯: {node_data.get('error', 'æœªçŸ¥é”™è¯¯')}"
                else:
                    log_output = f"âœ… [èŠ‚ç‚¹å®Œæˆ] {node_data['node_id']} - çŠ¶æ€: {status.upper()}"
            
            elif event_type == 'workflow_finished':
                wf_data = event_dict['data']
                log_output = f"ğŸ [å·¥ä½œæµå®Œæˆ] çŠ¶æ€: {wf_data['status'].upper()}\nè€—æ—¶: {wf_data['elapsed_time']}ç§’"
            
            return event_type, text_output, log_output
        
        except Exception as e:
            logger.error(f"äº‹ä»¶å¤„ç†é”™è¯¯: {str(e)}")
            return None

def show_stock_analysis(stock_code: str):
    """æ˜¾ç¤ºè‚¡ç¥¨åˆ†æå·¥ä½œæµé¡µé¢"""
    st.subheader("ğŸ“ˆ è‚¡ç¥¨æ™ºèƒ½åˆ†æ")
    st.markdown("""
    ä½¿ç”¨æ­¤å·¥å…·åˆ†æè‚¡ç¥¨æ•°æ®ã€‚è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œç³»ç»Ÿå°†æ‰§è¡Œåˆ†æå·¥ä½œæµå¹¶å®æ—¶æ˜¾ç¤ºç»“æœã€‚
    """)
    
    # stock_code = st.text_input("è‚¡ç¥¨ä»£ç ", "HK2018", key="analysis_input", 
    #                           help="è¯·è¾“å…¥è¦åˆ†æçš„è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼šHK2018")
    
    status_area = st.empty()
    result_area = st.empty()
    log_area = st.empty()
    
    if 'runner' not in st.session_state:
        st.session_state.runner = None
    if 'analysis_started' not in st.session_state:
        st.session_state.analysis_started = False
    
    # if st.button("å¼€å§‹åˆ†æ", type="primary", key="analysis_btn") and not st.session_state.analysis_started:
    #     st.session_state.analysis_started = True
    #     st.session_state.runner = WorkflowRunner(stock_code)
    #     threading.Thread(target=st.session_state.runner.run, daemon=True).start()
    
    if st.session_state.analysis_started and st.session_state.runner:
        status_area.info("ğŸš€ å·¥ä½œæµæ‰§è¡Œä¸­ï¼Œè¯·ç¨å€™...")
        result_placeholder = st.empty()
        log_placeholder = st.empty()
        
        full_text = ""
        full_log = ""
        
        while not st.session_state.runner.finished or not st.session_state.runner.text_queue.empty() or not st.session_state.runner.log_queue.empty():
            try:
                while not st.session_state.runner.text_queue.empty():
                    full_text = st.session_state.runner.text_queue.get()
                    result_placeholder.markdown(f"### åˆ†æç»“æœ\n{full_text}")
                
                while not st.session_state.runner.log_queue.empty():
                    log_entry = st.session_state.runner.log_queue.get()
                    full_log += log_entry + "\n\n"
                    log_placeholder.text_area("å·¥ä½œæµæ—¥å¿—", full_log, height=300)
                
                time.sleep(0.1)
            except queue.Empty:
                break
        
        if st.session_state.runner.finished:
            if st.session_state.runner.error:
                status_area.error(st.session_state.runner.error)
            else:
                status_area.success("âœ… åˆ†æå®Œæˆï¼")
                result_placeholder.markdown(f"### æœ€ç»ˆåˆ†æç»“æœ\n{full_text}")
                
                st.download_button(
                    label="ä¸‹è½½åˆ†ææŠ¥å‘Š",
                    data=full_text.encode('utf-8'),
                    file_name=f"{stock_code}_åˆ†ææŠ¥å‘Š.txt",
                    mime="text/plain"
                )
            
            st.session_state.analysis_started = False

def show_stock_data(stock_code: str):
    """æ˜¾ç¤ºè‚¡ç¥¨æ•°æ®é¡µé¢"""
    st.subheader("ğŸ“Š è‚¡ç¥¨æ•°æ®åˆ†æ")
    # stock_code = st.text_input("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç  (ä¾‹å¦‚: 600519,HK2018)", 
    #                           DEFAULT_STOCK_CODE, key="stock_input").strip()
    
    if not stock_code:
        st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
        return
        
    data_logger.info(f"ç”¨æˆ·æŸ¥è¯¢è‚¡ç¥¨: {stock_code}")
    
    info = display_stock_info(stock_code)
    if not info:
        return
        
    col1, col2 = st.columns(2)
    
    with col1:
        display_chart(stock_code, 'realtime')
    
    with col2:
        display_chart(stock_code, 'history')
    
    display_news(stock_code)

def main():
    """ä¸»åº”ç”¨å…¥å£"""
    st.title("ğŸ“Š æŠ•èµ„å°ç§˜")
    
    
    
    # ä¾§è¾¹æ è¯´æ˜
    stock_code = st.sidebar.text_input("è‚¡ç¥¨ä»£ç ", "HK2018", key="analysis_input", 
                              help="è¯·è¾“å…¥è¦åˆ†æçš„è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼šHK2018")
    
    if st.sidebar.button("å¼€å§‹åˆ†æ", type="primary", key="analysis_btn") and not st.session_state.analysis_started:
        st.session_state.analysis_started = True
        st.session_state.runner = WorkflowRunner(stock_code)
        threading.Thread(target=st.session_state.runner.run, daemon=True).start()

    st.sidebar.title("ä½¿ç”¨è¯´æ˜")
    st.sidebar.markdown("""
    ### åŠŸèƒ½è¯´æ˜
    1. **è‚¡ç¥¨æ•°æ®åˆ†æ**ï¼ˆä¸Šæ–¹ï¼‰ï¼š
       - æŸ¥çœ‹å®æ—¶è¡Œæƒ…å’Œå†å²Kçº¿å›¾
       - æµè§ˆæœ€æ–°ç›¸å…³æ–°é—»
    2. **è‚¡ç¥¨æ™ºèƒ½åˆ†æ**ï¼ˆä¸‹æ–¹ï¼‰ï¼š
       - ä½¿ç”¨AIå·¥ä½œæµç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š
       - å®æ—¶æ˜¾ç¤ºåˆ†æè¿‡ç¨‹å’Œç»“æœ
       - æ”¯æŒä¸‹è½½å®Œæ•´åˆ†ææŠ¥å‘Š

    ### æ³¨æ„äº‹é¡¹
    - è‚¡ç¥¨æ™ºèƒ½åˆ†æå¯èƒ½éœ€è¦1-3åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…
    - ç¡®ä¿è¾“å…¥æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ï¼šHK2018, 600519ï¼‰
    - åˆ†æè¿‡ç¨‹ä¸­è¯·ä¸è¦å…³é—­é¡µé¢
    """)

    # æ˜¾ç¤ºè‚¡ç¥¨æ•°æ®åˆ†æéƒ¨åˆ†
    show_stock_data(stock_code)
    
    # æ·»åŠ åˆ†éš”çº¿
    st.divider()
    
    # æ˜¾ç¤ºè‚¡ç¥¨æ™ºèƒ½åˆ†æéƒ¨åˆ†
    show_stock_analysis(stock_code)

if __name__ == "__main__":
    main()